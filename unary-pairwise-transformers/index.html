<!DOCTYPE HTML>
<!--
	Twenty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html id="top">
	<head>
		<title>Frederic Zhang - UPT</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../template/assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../template/assets/css/noscript.css" /></noscript>
	</head>
	<body class="index is-preload">
		<div id="page-wrapper">

			<!-- Header -->
				<header id="header" class="alt">
					<h1 id="logo"><a href="https://fredzzhang.com">Frederic Zhang</a></h1>
					<nav id="nav">
						<ul>
							<li class="current"><a href="#top">Return to Top</a></li>
							<li class="current"><a href="https://github.com/fredzzhang/upt">Github</a></li>
							<li class="current"><a href="">Preprint</a></li>
						</ul>
					</nav>
				</header>

			<!-- Banner -->
				<section id="banner" style="background-image: url('images/light-bl.svg'), url('images/light-br.svg'), url('images/overlay.png'), url('images/kangaroo.jpg');">

					<!--
						".inner" is set up as an inline-block so it automatically expands
						in both directions to fit whatever's inside it. This means it won't
						automatically wrap lines, so be sure to use line breaks where
						appropriate (<br />).
					-->
					<div class="inner">

						<header class="paper-title">
							<h2>Efficient Two-Stage Detection of Human&ndash;Object Interactions<br/>with a Novel Unary&ndash;Pairwise Transformer</h2>
						</header>
						<h3>Abstract</h3>
						<p class="paper-abstract">Recent developments in transformer models for visual data have led to significant improvements in recognition and detection tasks. In particular, using learnable queries in place of region proposals has given rise to a new class of one-stage detection models, spearheaded by the Detection Transformer (DETR). Variations on this one-stage approach have since dominated human&ndash;object interaction (HOI) detection. However, the success of such one-stage HOI detectors can largely be attributed to the representation power of transformers. We discovered that when equipped with the same transformer, their two-stage counterparts can be more performant and memory-efficient, while taking a fraction of the time to train. In this work, we propose the Unary&ndash;Pairwise Transformer, a two-stage detector that exploits unary and pairwise representations for HOIs. We observe that the unary and pairwise parts of our transformer network specialize, with the former preferentially increasing the scores of positive examples and the latter decreasing the scores of negative examples. We evaluate our method on the HICO-DET and V-COCO datasets, and significantly outperform state-of-the-art approaches.</p>
					</div>

				</section>

			<!-- Main -->
				<article id="main">

					<header class="special container">
						<span class="icon solid fa-chart-bar"></span>
						<div>
							<span class="author">
								<img class="avatar" src="images/fred.png"> <br/>
								<a href="https://fredzzhang.com/">Frederic Zhang</a>
							</span>
							<span class="author">
								<img class="avatar" src="images/dylan.png"> <br/>
								<a href="https://sites.google.com/view/djcampbell/">Dylan Campbell</a>
							</span>
							<span class="author">
								<img class="avatar" src="images/steve.png"> <br/>
								<a href="http://users.cecs.anu.edu.au/~sgould/">Stephen Gould</a>
							</span>
						</div>
						<div class="institute">The Australian National University&emsp;University of Oxford <br/>Australian Centre for Robotic Vision</div>
						<div>
							<a href="https://github.com/fredzzhang/upt"><span class="paper-link">
								<img class="logo" src="https://upload.wikimedia.org/wikipedia/commons/9/91/Octicons-mark-github.svg">
								<p>Code</p>
							</span></a>
							<a href="https://github.com/fredzzhang/upt"><span class="paper-link">
								<img class="logo" src="../images/paper.jpeg">
								<p>Preprint</p>
							</span></a>
							<a href="https://github.com/fredzzhang/upt"><span class="paper-link">
								<img class="logo" src="https://user-images.githubusercontent.com/11484831/102576019-afee1a80-4148-11eb-9dee-0efd9a6b98ba.png">
								<p>Video</p>
							</span></a>
						</div>
						<div>
							<img class="teaser" src="images/teaser.gif">
						</div>
					</header>
				</article>

			<!-- Footer -->
				<footer id="footer">

					<ul class="copyright">
						<li>&copy; 2021 Frederic Zhang</li>
					</ul>
				</footer>
		</div>

		<!-- Scripts -->
			<script src="../template/assets/js/jquery.min.js"></script>
			<script src="../template/assets/js/jquery.dropotron.min.js"></script>
			<script src="../template/assets/js/jquery.scrolly.min.js"></script>
			<script src="../template/assets/js/jquery.scrollex.min.js"></script>
			<script src="../template/assets/js/browser.min.js"></script>
			<script src="../template/assets/js/breakpoints.min.js"></script>
			<script src="../template/assets/js/util.js"></script>
			<script src="../template/assets/js/main.js"></script>

	</body>
</html>